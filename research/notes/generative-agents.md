# Generative Agents: Interactive Simulacra of Human Behavior

**Authors:** Joon Sung Park, Joseph C. O'Brien, et al. (Stanford + Google)  
**Year:** 2023  
**Link:** https://arxiv.org/abs/2304.03442  
**Read Date:** 2025-02-18

## ðŸŽ¯ Main Contribution
Agents with memory, reflection, and planning can exhibit surprisingly human-like emergent social behaviors in a simulated environment (like The Sims).

## ðŸ’¡ Key Insights
- **Memory stream**: Sequential record of observations (like JARVIS notes!)
- **Retrieval**: Fetch relevant memories based on recency, importance, relevance
- **Reflection**: Agents periodically synthesize memories into higher-level insights
- **Planning**: Agents create and update plans based on context
- Emergent behaviors: Relationships, coordination, surprises none of which were explicitly programmed
- 25 agents in a town â†’ realistic social dynamics

## ðŸ”¬ Methodology
**Architecture has 3 key components:**

1. **Memory Stream**
   - Everything the agent experiences gets logged
   - Tagged with timestamp and importance score
   - Retrieved using recency + relevance + importance

2. **Reflection**
   - Every 100 observations, agent reflects
   - Generates high-level insights from recent memories
   - These insights are stored back in memory
   - Example: "Klaus is getting close to Maria" (from many small observations)

3. **Planning**
   - Agent has a daily plan
   - Updates reactively based on observations
   - Plans influence what agent pays attention to

**Sound familiar? This is basically JARVIS!**

## ðŸ“Š Results
- Agents throw a party and actually invite each other
- Romantic relationships form naturally
- Information spreads realistically through social network
- Agents coordinate complex activities without explicit coordination rules
- Believability rated highly by humans

## ðŸ¤” Relevance to My Research
**INCREDIBLY RELEVANT FOR PHASE 3 (EMERGENCE)!**

This is literally what I want to study:
- Multiple agents
- Shared memory space (like JARVIS memory)
- No explicit coordination
- Emergent collaboration patterns

**Key insight**: Retrieval algorithm matters!
- Recency: Recent memories weighted higher
- Importance: Some observations matter more
- Relevance: Similarity to current context

## ðŸ’­ How This Applies to My Work

**For Debate (Phase 1):**
- Agents could remember past debates
- Learn from previous critiques
- Build on earlier discussions

**For Emergence (Phase 3):**
- **This is the model!**
- Give each agent a memory stream
- Let them retrieve relevant context
- See if coordination emerges
- Measure: Do they develop roles? Patterns? Strategies?

**Architecture Parallel:**
```
Generative Agents          My System
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€
Memory Stream        â†’     JARVIS notes
Retrieval            â†’     search_notes()
Reflection           â†’     Could add this!
Planning             â†’     Agent decide when to act
Multiple agents      â†’     My multi-agent system
Emergence            â†’     Phase 3 research!
```

## ðŸ“Œ Quotes
> "We demonstrate that generative agents produce believable individual and emergent social behaviors... agents seek to coordinate with each other on a large creative project."

> "The retrieval function scores all memories based on recency, importance, and relevance."

## ðŸ”— Implementation Ideas

**Immediate (for debate):**
- Add memory to debate agents
- Let critic retrieve past successful critiques
- See if debate improves over multiple tasks

**Phase 3 (emergence):**
- Give each agent their own memory stream
- Share workspace (like JARVIS shared memory)
- Implement their retrieval algorithm:
```python
  def retrieve(query, memories):
      for m in memories:
          score = (
              recency_score(m) + 
              importance_score(m) + 
              relevance_score(m, query)
          )
      return top_k(memories, by=score)
```
- Let agents decide when to contribute (not forced turns)
- Measure emergent patterns

**Key question to test:**
"Can code-writing agents develop collaboration strategies like the social agents did?"

## ðŸŽ¯ Next Steps
- [ ] Implement basic memory retrieval for agents
- [ ] Add reflection mechanism (synthesize learnings)
- [ ] Design emergence experiment based on their framework
- [ ] Compare: explicit structure vs emergent

## Related Papers
- ReAct (reasoning + acting)
- AutoGPT (autonomous agents)
- MemGPT (memory as OS for LLMs)
